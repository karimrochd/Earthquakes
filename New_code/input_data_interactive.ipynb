{
 "cells": [
  {
   "cell_type": "code",
   "id": "2169392c235ba55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:27:00.025792Z",
     "start_time": "2024-07-15T12:26:59.040622Z"
    }
   },
   "source": [
    "\n",
    "from importlib import reload\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import utilities\n",
    "\n",
    "reload(utilities)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utilities' from \"/Users/gloirelinvani/Library/Mobile Documents/com~apple~CloudDocs/School/MagisteÌ€re d'Informatique/LDD3/S6/Stage/Earthquakes/earthquakes/New_code/utilities.py\">"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Functions to build displacement maps and labels for each main shock in input HDF5 file",
   "id": "1a1289c012861c9d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:27:00.035333Z",
     "start_time": "2024-07-15T12:27:00.026578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Global variables:\n",
    "n_seq_init = 0  # Number of sequences processed\n",
    "n_seq_discarded = 0  # Number of sequences discarded\n",
    "\n",
    "\n",
    "def process_main_shock_data(hdf5_file_path, output_path):\n",
    "    \"\"\"Process main shocks data to generate interpolated displacement maps.\"\"\"\n",
    "    with h5py.File(hdf5_file_path, 'r') as file:\n",
    "        for id_seq in file.keys():\n",
    "            process_single_main_shock(file[id_seq], output_path, id_seq)\n",
    "\n",
    "\n",
    "def process_single_main_shock(main_shock_group, output_path, id_seq):\n",
    "    global n_seq_init, n_seq_discarded\n",
    "    n_seq_init += 1\n",
    "    print(f\"Processing main shock {id_seq}...\")\n",
    "    gps_stations_displacements = main_shock_group['gps_stations_displacements'][()]\n",
    "    # For each station, multiply the displacement by the scale factor and sum the displacements\n",
    "    # over the time dimension\n",
    "    ## gps_stations_displacements: (NbStations, NbDays, Displacement(X,Y,Z))\n",
    "    gps_stations_displacements *= scale_factor  ## convert to mm\n",
    "    gps_stations_displacements = gps_stations_displacements.reshape(-1, 3)  ## (NbStations, (X,Y,Z))\n",
    "    gps_stations_positions = main_shock_group['stations_positions'][()]\n",
    "    main_shock_location = main_shock_group.attrs['main_shock_location']\n",
    "    after_shocks_locations = main_shock_group['aftershocks_locations'][()]\n",
    "    after_shocks_locations = after_shocks_locations.reshape(-1, 2)  ## (NbAfterShocks, (X,Y))\n",
    "    main_shock_day = main_shock_group.attrs['main_shock_day']\n",
    "    main_shock_mag = main_shock_group.attrs['main_shock_magnitude']\n",
    "\n",
    "    # Calculate the interpolation grid\n",
    "    min_lat, max_lat, min_lon, max_lon, n_pixels_lat, n_pixels_lon = utilities.calculate_interpolation_grid(\n",
    "        main_shock_location, cell_size_degs, int(num_cells / 2)\n",
    "    )\n",
    "\n",
    "    # Number of stations inside the grid\n",
    "    # n_stations_inside_grid = ((gps_stations_positions[:, 0] >= min_lat) & (gps_stations_positions[:, 0] <= max_lat) &\n",
    "    #                           (gps_stations_positions[:, 1] >= min_lon) & (\n",
    "    #                                       gps_stations_positions[:, 1] <= max_lon)).sum()\n",
    "    # \n",
    "    # # Skip if not enough stations\n",
    "    # if n_stations_inside_grid < min_stations_inside:\n",
    "    #     n_seq_discarded += 1\n",
    "    #     print('Skipping:', id_seq, 'with only', n_stations_inside_grid,\n",
    "    #           'stations inside the grid, out of total (downloaded) ',\n",
    "    #           gps_stations_positions.shape[0])\n",
    "    #     return\n",
    "\n",
    "    # labels\n",
    "    labels = np.zeros((n_pixels_lat, n_pixels_lon))\n",
    "    # discretize the aftershocks \n",
    "    aftershocks_rows = ((after_shocks_locations[:, 0] - min_lat) / cell_size_degs).astype('int')\n",
    "    aftershocks_cols = ((after_shocks_locations[:, 1] - min_lon) / cell_size_degs).astype('int')\n",
    "    # mask to make sure no event is outside the grid\n",
    "    aftershocks_mask = (aftershocks_rows < n_pixels_lat) & (aftershocks_rows >= 0) & (\n",
    "            aftershocks_cols < n_pixels_lon) & (\n",
    "                               aftershocks_cols >= 0)\n",
    "    aftershocks_rows = aftershocks_rows[aftershocks_mask]\n",
    "    aftershocks_cols = aftershocks_cols[aftershocks_mask]\n",
    "    # Metadata on aftershocks inside the grid for the plots\n",
    "    grid_after_shocks_locations = after_shocks_locations[aftershocks_mask]\n",
    "    grid_after_shocks_magnitudes = main_shock_group['aftershocks_magnitudes'][()][aftershocks_mask]\n",
    "    if aftershocks_mask.sum() == 0:\n",
    "        n_seq_discarded += 1\n",
    "        print('Skipping:', id_seq, 'with no aftershocks inside the grid')\n",
    "        return\n",
    "\n",
    "    if not regression:\n",
    "        if soft_labels:\n",
    "            utilities.create_classification_soft_labels(labels, aftershocks_rows, aftershocks_cols, cell_size_rads,\n",
    "                                                        sigma_softlabels * cell_size_rads)\n",
    "        else:\n",
    "            labels[aftershocks_rows, aftershocks_cols] = 1\n",
    "    else:\n",
    "        seismic_moments = 10 ** (\n",
    "                1.5 * grid_after_shocks_magnitudes + 6.07)  # aftershocks magnitudes converted to their seismic moments\n",
    "        if soft_labels:\n",
    "            utilities.create_regression_soft_labels(labels, seismic_moments,\n",
    "                                                    aftershocks_rows, aftershocks_cols, cell_size_rads,\n",
    "                                                    sigma_softlabels * cell_size_rads)\n",
    "        else:\n",
    "            #print(aftershocks_rows)\n",
    "            #print(aftershocks_cols)\n",
    "            np.add.at(labels, (aftershocks_rows, aftershocks_cols),\n",
    "                      seismic_moments)  # add the seismic moments to the grid (sum of seismic moments in case of multiple aftershocks in the same pixel)\n",
    "            #print(\"Seismic moments\", seismic_moments)\n",
    "            #print(grid_after_shocks_magnitudes)\n",
    "            #print(labels[aftershocks_rows, aftershocks_cols])\n",
    "            #sys.exit()\n",
    "\n",
    "    # The grid of interpolated displacements: channel shape (X,Y,Z, distance pixel-MS, flag to indicate if the pixel is valid or not)\n",
    "    interpolated_displacements = np.zeros((n_pixels_lat, n_pixels_lon,\n",
    "                                           5))\n",
    "    if elasticity:\n",
    "        try:\n",
    "            gps_stations_displacements_means = gps_stations_displacements.mean(axis=0)\n",
    "            gps_stations_displacements_stds = gps_stations_displacements.std(axis=0)\n",
    "            gps_stations_displacements_standardized = (\n",
    "                                                              gps_stations_displacements - gps_stations_displacements_means) / gps_stations_displacements_stds\n",
    "            # gps_stations_displacements_standardized = zscore(gps_stations_displacements, axis=0) # Standardize the displacements\n",
    "            automatic_reg_factor = 2  #minimal_distances[id]/cell_size_km\n",
    "\n",
    "            utilities.elasticity_interpolation(\n",
    "                interpolated_displacements,\n",
    "                np.pi * main_shock_location / 180,\n",
    "                np.pi * gps_stations_positions / 180,\n",
    "                gps_stations_displacements_standardized,\n",
    "                n_pixels_lat, n_pixels_lon,\n",
    "                np.pi * min_lat / 180,\n",
    "                np.pi * min_lon / 180,\n",
    "                cell_size_rads,\n",
    "                sigma_rads,\n",
    "                min_station_pixel_distance_km,\n",
    "                reg_factor=automatic_reg_factor,\n",
    "                index_ratio=0.8)\n",
    "\n",
    "            interpolated_displacements[:, :, :2] *= gps_stations_displacements_stds[:2]\n",
    "            interpolated_displacements[:, :, :2] += gps_stations_displacements_means[:2]\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    else:\n",
    "        utilities.interpolate_displacements(\n",
    "            interpolated_displacements,\n",
    "            np.pi * main_shock_location / 180,\n",
    "            np.pi * gps_stations_positions / 180,\n",
    "            gps_stations_displacements,\n",
    "            n_pixels_lat, n_pixels_lon,\n",
    "            np.pi * min_lat / 180,\n",
    "            np.pi * min_lon / 180,\n",
    "            cell_size_rads,\n",
    "            sigma_rads,\n",
    "            min_station_pixel_distance_km,\n",
    "        )\n",
    "    #Save the interpolated data and labels to the output file\n",
    "    save_interpolated_data(interpolated_displacements, labels, output_path, id_seq, main_shock_day, main_shock_mag,\n",
    "                           main_shock_location, grid_after_shocks_locations, grid_after_shocks_magnitudes,\n",
    "                           gps_stations_positions)\n",
    "\n",
    "\n",
    "def save_interpolated_data(interpolated_data, labels, output_path, main_shock_id, main_shock_day, main_shock_mag,\n",
    "                           main_shock_location, grid_after_shocks_locations, grid_after_shocks_magnitudes,\n",
    "                           gps_stations_positions):\n",
    "    with h5py.File(output_path, 'a') as f:\n",
    "        if str(main_shock_id) in f:\n",
    "            del f[str(main_shock_id)]\n",
    "        grp = f.create_group(str(main_shock_id))\n",
    "        grp.attrs['main_shock_day'] = main_shock_day\n",
    "        grp.attrs['main_shock_magnitude'] = main_shock_mag\n",
    "        # For the plots\n",
    "        grp.attrs['main_shock_location'] = main_shock_location\n",
    "\n",
    "        grp.create_dataset('interpolated_displacement', data=interpolated_data)\n",
    "        grp.create_dataset('labels', data=labels)\n",
    "        # Metadata for the plots\n",
    "        grp.create_dataset('grid_after_shocks_locations', data=grid_after_shocks_locations)\n",
    "        grp.create_dataset('grid_after_shocks_magnitudes', data=grid_after_shocks_magnitudes)\n",
    "        grp.create_dataset('gps_station_positions', data=gps_stations_positions)"
   ],
   "id": "358ab6a9ad313987",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Parameters",
   "id": "bb323ca0c7dc7c7a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:27:26.475937Z",
     "start_time": "2024-07-15T12:27:26.461747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "earth_radius_km = 6371  # km\n",
    "grid_size_km = 250  # Size of the square grid in km\n",
    "cell_size_km = 5  #Cell size in km\n",
    "cell_size_rads = cell_size_km / earth_radius_km  # Cell size in radians\n",
    "cell_size_degs = cell_size_rads * 180 / np.pi\n",
    "scale_factor = 1e6  # Scale factor for the coordinates from km to mm\n",
    "num_cells = int(grid_size_km / cell_size_km)  # number of cells in the lateral direction\n",
    "#min_stations_inside = 3  # minimal number of stations inside the grid\n",
    "soft_labels = False  ## smoothed labels (smoothed over space)\n",
    "regression = False  ## regression instead of classification\n",
    "elasticity = True  # Thin 2D elastic sheet model for interpolating GPS data\n",
    "sigma_softlabels = 1  # sigma for the gaussian smoothing of the labels, expressed in number of cell sizes\n",
    "sigma_interpolation = 8  ## expressed in number of cell sizes\n",
    "sigma_rads = sigma_interpolation * cell_size_rads  # sigma for the gaussian interpolation\n",
    "min_station_pixel_distance_km = 86  # minimal distance between station and pixel in km\n",
    "hdf5_in_put_file_path = \"Data/Displacements_min_mainshock_mag=6_min_stations_per_main_shock=3_regression=True_min_after_shock_mag=2.5_after_shock_time_window=45_n_days_before_mainshock=1_n_days_after_mainshock=1_min_days_between_mainshocks=30_grid_size_km=250.hdf5\"  #Path to the HDF5 output file\n",
    "hdf5_out_put_file_path = (\n",
    "    f\"Data/Interpolated_Data_reg={regression}_soft_labels={soft_labels}_elasticity={elasticity}_min_mainshock_mag=6_min_stations_per_main_shock=3_min_after_shock_mag=4_after_shock_time_window=45_n_days_before_mainshock=1_n_days_after_mainshock=1.hdf5\")  #Path to the HDF5 output file"
   ],
   "id": "36dbf5d803b28b9e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "cc53cc4760033a61",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "id": "839cf2c4c91b58bf",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-07-15T12:27:28.086069Z"
    }
   },
   "source": [
    "def main():\n",
    "    process_main_shock_data(hdf5_in_put_file_path, hdf5_out_put_file_path)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    print('Number of sequences processed:', n_seq_init)\n",
    "    print('Number of sequences discarded:', n_seq_discarded)\n",
    "    print('Number of sequences kept:', n_seq_init - n_seq_discarded)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing main shock 103...\n",
      "Processing main shock 109...\n",
      "Processing main shock 114...\n",
      "Processing main shock 118...\n",
      "Processing main shock 151...\n",
      "Processing main shock 155...\n",
      "Processing main shock 156...\n",
      "Processing main shock 158...\n",
      "Processing main shock 161...\n",
      "Processing main shock 163...\n",
      "Processing main shock 172...\n",
      "Processing main shock 174...\n",
      "Processing main shock 176...\n",
      "Processing main shock 179...\n",
      "Processing main shock 181...\n",
      "Processing main shock 182...\n",
      "Processing main shock 187...\n",
      "Processing main shock 194...\n",
      "Processing main shock 198...\n",
      "Processing main shock 199...\n",
      "Processing main shock 200...\n",
      "Processing main shock 203...\n",
      "Processing main shock 204...\n",
      "Processing main shock 206...\n",
      "Processing main shock 207...\n",
      "Processing main shock 213...\n",
      "Processing main shock 214...\n",
      "Processing main shock 215...\n",
      "Processing main shock 217...\n",
      "Processing main shock 218...\n",
      "Processing main shock 219...\n",
      "Processing main shock 226...\n",
      "Processing main shock 233...\n",
      "Processing main shock 248...\n",
      "Processing main shock 251...\n",
      "Processing main shock 252...\n",
      "Processing main shock 256...\n",
      "Processing main shock 257...\n",
      "Processing main shock 265...\n",
      "Processing main shock 267...\n",
      "Processing main shock 271...\n",
      "Processing main shock 275...\n",
      "Processing main shock 277...\n",
      "Processing main shock 279...\n",
      "Processing main shock 280...\n",
      "Processing main shock 282...\n",
      "Processing main shock 283...\n",
      "Processing main shock 284...\n",
      "Processing main shock 285...\n",
      "Processing main shock 291...\n",
      "Processing main shock 293...\n",
      "Processing main shock 294...\n",
      "Processing main shock 295...\n",
      "Processing main shock 296...\n",
      "Processing main shock 297...\n",
      "Processing main shock 299...\n",
      "Processing main shock 300...\n",
      "Processing main shock 302...\n",
      "Processing main shock 306...\n",
      "Processing main shock 308...\n",
      "Processing main shock 311...\n",
      "Processing main shock 312...\n",
      "Processing main shock 314...\n",
      "Processing main shock 315...\n",
      "Processing main shock 317...\n",
      "Processing main shock 318...\n",
      "Processing main shock 319...\n",
      "Processing main shock 321...\n",
      "Processing main shock 324...\n",
      "Processing main shock 325...\n",
      "Processing main shock 335...\n",
      "Processing main shock 352...\n",
      "Processing main shock 376...\n",
      "Processing main shock 378...\n",
      "Processing main shock 392...\n",
      "Processing main shock 393...\n",
      "Processing main shock 410...\n",
      "Processing main shock 414...\n",
      "Processing main shock 415...\n",
      "Processing main shock 418...\n",
      "Processing main shock 420...\n",
      "Processing main shock 422...\n",
      "Processing main shock 424...\n",
      "Processing main shock 426...\n",
      "Processing main shock 427...\n",
      "Processing main shock 429...\n",
      "Processing main shock 432...\n",
      "Processing main shock 433...\n",
      "Processing main shock 435...\n",
      "Processing main shock 436...\n",
      "Processing main shock 437...\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "adbcf4e7afa43036"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
